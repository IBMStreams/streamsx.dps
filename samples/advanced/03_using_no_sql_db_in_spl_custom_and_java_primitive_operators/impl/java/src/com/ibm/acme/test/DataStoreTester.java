/* Generated by Streams Studio: February 27, 2015 1:43:48 AM EST */
package com.ibm.acme.test;


import org.apache.log4j.Logger;

import com.ibm.streamsx.dps.*;
import com.ibm.streamsx.dl.*;
import com.ibm.streams.operator.AbstractOperator;
import com.ibm.streams.operator.OperatorContext;
import com.ibm.streams.operator.OutputTuple;
import com.ibm.streams.operator.StreamingData.Punctuation;
import com.ibm.streams.operator.StreamingInput;
import com.ibm.streams.operator.StreamingOutput;
import com.ibm.streams.operator.Tuple;
import com.ibm.streams.operator.model.InputPortSet;
import com.ibm.streams.operator.model.InputPortSet.WindowMode;
import com.ibm.streams.operator.model.InputPortSet.WindowPunctuationInputMode;
import com.ibm.streams.operator.model.InputPorts;
import com.ibm.streams.operator.model.Libraries;
import com.ibm.streams.operator.model.OutputPortSet;
import com.ibm.streams.operator.model.OutputPortSet.WindowPunctuationOutputMode;
import com.ibm.streams.operator.model.OutputPorts;
import com.ibm.streams.operator.model.PrimitiveOperator;
import com.ibm.streams.operator.model.SharedLoader;

/**
 * Class for an operator that receives a tuple and then optionally submits a tuple. 
 * This pattern supports one or more input streams and one or more output streams. 
 * <P>
 * The following event methods from the Operator interface can be called:
 * </p>
 * <ul>
 * <li><code>initialize()</code> to perform operator initialization</li>
 * <li>allPortsReady() notification indicates the operator's ports are ready to process and submit tuples</li> 
 * <li>process() handles a tuple arriving on an input port 
 * <li>processPuncuation() handles a punctuation mark arriving on an input port 
 * <li>shutdown() to shutdown the operator. A shutdown request may occur at any time, 
 * such as a request to stop a PE or cancel a job. 
 * Thus the shutdown() may occur while the operator is processing tuples, punctuation marks, 
 * or even during port ready notification.</li>
 * </ul>
 * <p>With the exception of operator initialization, all the other events may occur concurrently with each other, 
 * which lead to these methods being called concurrently by different threads.</p> 
 */
@PrimitiveOperator(name="DataStoreTester", namespace="com.ibm.acme.test",
description="Java Operator DataStoreTester")
@InputPorts({@InputPortSet(description="Port that ingests tuples", cardinality=1, optional=false, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious), @InputPortSet(description="Optional input ports", optional=true, windowingMode=WindowMode.NonWindowed, windowPunctuationInputMode=WindowPunctuationInputMode.Oblivious)})
@OutputPorts({@OutputPortSet(description="Port that produces tuples", cardinality=1, optional=false, windowPunctuationOutputMode=WindowPunctuationOutputMode.Generating), @OutputPortSet(description="Optional output ports", optional=true, windowPunctuationOutputMode=WindowPunctuationOutputMode.Generating)})
//Add the DPS toolkit's Java library (dps-helper.jar) to the path of this operator.
//There are 2 ways to do this:
//1. If your application will have access to the Streams install location at runtime, then you can specify the full path to the location of the dps-helper.jar file present inside the DPS toolkit as follows:
@Libraries("@STREAMS_INSTALL@/toolkits/com.ibm.streamsx.dps/impl/java/lib/dps-helper.jar")
//if that path will be accessible at runtime. 
//2. Or, you can copy the dps-helper.jar from <STREAMS_INTSALL>/toolkits/com.ibm.streamsx.dps/impl/java/lib/dps-helper.jar into the lib folder of this application and reference it as follows:
//@Libraries("lib/dps-helper.jar")

// Add the following annotation if you are going to fuse this Java operator with other Java operators that will also use
// the DPS APIs. In that case, it is necessary to add the following annotation so that the fused PE will use a shared class loader.
// This annotation is typically effective only when all the fused Java operators have exactly the 
// same entries in their @Libraries annotation (That rule is from Java and not from Streams). 
// If you don't have this annotation, it will give a runtime exception by trying to load the DPS .so library multiple times
// from within a single fused PE.
//
// Exception in thread "Thread-17" java.lang.UnsatisfiedLinkError: /homes/hny5/sen/workspace27/062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators/output/com.acme.test.Main/Standalone/../../../../com.ibm.streamsx.dps/impl/java/bin/../../lib/x86_64.RHEL6/libDpsJavaLibLoader.so (Library is already loaded in another ClassLoader)
// at java.lang.ClassLoader.loadLibraryWithPath(ClassLoader.java:1217)
//
// If you can't use a shared class loader in your project for other technical reasons, then remove the following annotation line and search for 
// "FusedCondition" inside the DpsHelper.java (in the DPS toolkit impl/java/src directory). Read the commentary there to make
// the necessary code changes in that file for having fused Java operators access the DPS APIs. Then, rebuild the dps-helper.jar file
// to have a workaround for the fused Java operators' access of the DPS within their processing logic.
//
@SharedLoader(true)
public class DataStoreTester extends AbstractOperator {
	// Declare a member variable to hold the instance of the dps store factory object.
	private StoreFactory sf = null;
	// Declare a member variable to hold the instance of the distributed lock factory object.
	private LockFactory lf = null;
	
    /**
     * Initialize this operator. Called once before any tuples are processed.
     * @param context OperatorContext for this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
	@Override
	public synchronized void initialize(OperatorContext context)
			throws Exception {
    	// Must call super.initialize(context) to correctly setup an operator.
		super.initialize(context);
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " initializing in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        
        // TODO:
        // If needed, insert code to establish connections or resources to communicate an external system or data store.
        // The configuration information for this may come from parameters supplied to the operator invocation, 
        // or external configuration files or a combination of the two.
        
        // We must first call this initialize method before using any other API from the DPS toolkit.
        // We have a choice to either use the default DPS config file inside this application directory (etc/no-sql-kv-store-servers.cfg)  
        // or a DPS config file available from a different directory (/tmp/my-dps-config-file.cfg) outside of this application's directory structure.
        // 1) In the case of using the default DPS config file, we can  simply call initialize().
        // 2) In the case of using a different DPS file located elsewhere, we can call initialize("/mydir/somefile.txt").
     	DistributedStores.initialize();
        // DistributedStores.initialize("/tmp/my-dps-config.txt");

     	// Get a store factory to create and operate on stores.
        sf = DistributedStores.getStoreFactory();
        // We have to get a lock factory for creating/acquiring/releasing/removing distributed locks as needed inside this Java primitive operator.
        lf = DistributedLocks.getLockFactory(); 
	}

    /**
     * Notification that initialization is complete and all input and output ports 
     * are connected and ready to receive and submit tuples.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public synchronized void allPortsReady() throws Exception {
    	// This method is commonly used by source operators. 
    	// Operators that process incoming tuples generally do not need this notification. 
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " all ports are ready in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
    }

    /**
     * Process an incoming tuple that arrived on the specified port.
     * <P>
     * Copy the incoming tuple to a new output tuple and submit to the output port. 
     * </P>
     * @param inputStream Port the tuple is arriving on.
     * @param tuple Object representing the incoming tuple.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public final void process(StreamingInput<Tuple> inputStream, Tuple tuple)
            throws Exception {
        String dbProductName = sf.getNoSqlDbProductName();
        // Get the details about the machine where this operator is running.
        // This method returns a String array with 3 elements.
        // Each element will carry the value for machine name, os version, cpu architecture in that order.
        String [] machineDetails = new String[3];
        machineDetails = sf.getDetailsAboutThisMachine();
        // Display the NoSQL DB product name being used for this test run.
        System.out.println("=====================================================");
        System.out.println("Details about this DPS client machine:");
        System.out.println("NoSQL K/V store product name: " + dbProductName);
        System.out.println("Machine name: " + machineDetails[0]);
        System.out.println("OS version: " + machineDetails[1]);
        System.out.println("CPU architecture: " + machineDetails[2]);
        System.out.println("=====================================================");   
    	// Create a new tuple for output port 0
        StreamingOutput<OutputTuple> outStream = getOutput(0);
        OutputTuple outTuple = outStream.newTuple();

        // Copy across all matching attributes.
        outTuple.assign(tuple);

        // TODO: Insert code to perform transformation on output tuple as needed:
        outTuple.setString("dpsTesterName", "DPS Tester 567");

        // Submit new tuple to output port 0
        outStream.submit(outTuple);
    }
    
    /**
     * Process an incoming punctuation that arrived on the specified port.
     * @param stream Port the punctuation is arriving on.
     * @param mark The punctuation mark
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    @Override
    public void processPunctuation(StreamingInput<Tuple> stream,
    		Punctuation mark) throws Exception {
    	// For window markers, punctuate all output ports 
    	super.processPunctuation(stream, mark);
    }

    /**
     * Shutdown this operator.
     * @throws Exception Operator failure, will cause the enclosing PE to terminate.
     */
    public synchronized void shutdown() throws Exception {
        OperatorContext context = getOperatorContext();
        Logger.getLogger(this.getClass()).trace("Operator " + context.getName() + " shutting down in PE: " + context.getPE().getPEId() + " in Job: " + context.getPE().getJobId() );
        
        // TODO: If needed, close connections or release resources related to any external system or data store.

        // Must call super.shutdown()
        super.shutdown();
    }
}
