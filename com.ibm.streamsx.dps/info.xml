<?xml version="1.0" encoding="UTF-8"?>
<info:toolkitInfoModel xmlns:common="http://www.ibm.com/xmlns/prod/streams/spl/common" xmlns:info="http://www.ibm.com/xmlns/prod/streams/spl/toolkitInfo">
  <info:identity>
    <info:name>com.ibm.streamsx.dps</info:name>
    <info:description>The Distributed Process Store (DPS) toolkit enables multiple applications running processing elements (PEs) on one or more machines to share application specific state information. 
The shared information is stored in an external data store. This allows non-fused SPL, C++ and Java operators running on different machines to share information. 
The RedisÂ® NoSQL Key-Value (K/V) data store is the only officially supported data store for the DPS toolkit. Please note that the Redis store is an open source offering requiring acceptance of its BSD license. Currently, only Redis 2.8.2+ and Redis 3 are supported.  
See the [http://redis.io/ | Redis home page] for information on how to download, install and configure a Redis server or cluster.
The toolkit consists of a set of native functions that provide access to shared state, and additional locking functionality to provide safe, concurrent access to the shared data.
These functions can be used from anywhere inside a Streams application, whether it be SPL code, SPL functions, SPL native functions, C++ primitive operators.  They also have counterparts written in Java that can be used from a Java primitive operator.
The actual state information is stored separately in the Redis distributed back-end in-memory store which is transparent to the Streams application. 

# Conceptual Overview
The following diagram provides a conceptual overview of the interaction between the Streams application, the DPS toolkit, and the Redis distributed back-end in-memory store. Each green box represents a processing element (PE) of the application. These interconnected PEs have access to the DPS logical container as well as full access to the data store APIs. 
In the logical view layer, code abstraction is done for these four important aspects:
* Serialization required before storing the user data in the store
* Deserialization required after fetching the data from the store and just before returning it to the user
* In-memory database abstraction in order to integrate the Redis store with the Distributed Process Store
* Platform dependent implementation necessary to communicate with the Redis back-end in-memory store 
Any PE, regardless of whether it originally created the store and populated it with its original contents (if any), can safely access the store (shown in the physical view layer) to save and retrieve contents. To access the store, the PE requires a valid store name or a store handle. 

{doc/icons/overview.png}

As shown in the figure above, an instance of the DPS accommodates one or more user-created stores. 
Each store can hold an unlimited number of data items stored as key-value pairs created using any SPL type as a key and any SPL type as a value.
Additionally, a DPS instance contains a store factory that can manufacture stores on demand.
Similarly, any store can be accessed concurrently by any number of PEs running on different machines. 
In order to ensure safe access (i.e. store operations do not override each other), each DPS instance contains a lock factory enabling you to create shareable locks for the purpose of locking a store during a critical private operation and then releasing the lock once that critical store operation has completed.


	
# Toolkit overview

The functions provided by the DPS toolkit are divided into 3 categories:

* User created data stores, 
* TTL global store, in which  pairs can be configured to expire after a certain time period,
* Distributed lock API
Note: The toolkit provides the aforementioned functionality as native functions that can be used from C++ and SPL applications and  through a fully object oriented Java API. 
The comments below apply regardless of the programming language being used.  

# User Created Stores
A DPS store is a container in which  pairs can be created, retrieved from, updated and deleted. The keys and values must be a SPL primitive type, such as `rstring` or `int32`, or a SPL composite type such as a `map`. 
You can perform Create, Read, Update, Delete (CRUD) operations simultaneously on numerous stores that you own, share, and manage within the context of one or more Streams applications.
You can create your own stores and share application-specific data across multiple Streams processing elements (PEs) and across multiple Streams applications running on one or more machines.
The key-value pairs are kept inside each individual user-created stores. Applications can create and use many such user specified stores at the same time. There is also support for running arbitrary one-way data store commands from within your application. See the `dpsRunDataStoreCommand()` functions.
The core functions needed to manage the lifecycle of a DPS store in a SPL application are in the com.ibm.streamsx.store.distributed namespace.
These functions allow you to perform operations such as create/get/remove stores, put/get/check key value pairs, iterate over the store, serialize/deserialize stores.  

# Time to Live (TTL) Store

The toolkit also provides a set of functions for storing key-value pairs that are configured to expire after a certain time period.  
When the pre-assigned TTL value expires, these data items will be automatically removed from the data store.  Key Value pairs stored and obtained using these functions will not belong to any user created stores. Instead, they will be stored at the top level global area of the configured Redis back-end.
When applications have a need to put data items with a TTL value and get them back, you can use these functions without having to create individual stores.  These functions all have a "TTL" suffix.
These ephemeral key value pairs can only be used with the aforementioned functions and cannot be used with  any functions that take store name or store id as a function argument.

A non-zero TTL value passed to these functions will automatically remove the key-value pairs at the end of their specified lifetime.
A TTL value of zero will keep the key-value pair in the back-end data store forever or until such time as they are removed manually using the `dpsRemoveTTL()` function.

These functions will return true or false indicating whether the operation succeeded or not. In the case of a false return value, an error code and an error string can be obtained. 
In the Redis back-end data store, TTL based data items can coexist with other user created stores containing data items that could live forever. 
Such TTL based APIs only provide a limited set of functions (put, get, has, and remove), but at the same time will have a slightly lower overhead than the feature rich non-TTL based functions.


# Distributed Locking API

The DPS Toolkit also provides the following distributed locking functions which can be used for accessing stores from multiple threads and multiple processes safely without overriding each other. 
This is achieved using a trust based cooperative locking scheme to gain exclusive access into the stores for performing a set of transaction based store activities.


+ Developing and running applications that use the DPS Toolkit


To create applications that use the DPS Toolkit, you'll need to:
1.  Install IBM InfoSphere Streams.  Configure the product environment variables by entering the following command: 
      source product-installation-root-directory/4.1.0.0/bin/streamsprofile.sh
2.  Ensure that all of the following additional RPMs required by the DPS toolkit are present on your system: 
 * curl
 * curl-devel
 * lua
 * lua-devel
 * openssl-devel
 * openldap-devel
3. Install and configure a supported version of Redis. See [http://redis.io/topics/admin] for Redis store Linux administration requirements.  
 
 **Additional notes for Redis**
 * Redis 2.8.x: With this version of Redis, the DPS toolkit supports a multi-server setup. If you have multiple Redis servers configured, using the DPS Time To Live (TTL) APIs will result in better scalability of your put/get requests than using the APIs that take the user created store id as a function argument. Choose the APIs according to your functional and scaling needs. While running multiple Redis server instances either on a single machine or on multiple machines, the DPS logic will automatically shard (or distribute) the put/get workload to different Redis server instance. With the Redis v2.8.x data store, you can manually configure and start multiple instances of Redis to listen and run on different ports and machines. The DPS toolkit will internally treat these Redis v2.8.x multiple instances as multiple shards and distribute the key-value pairs among those instances to improve performance with increased memory capacity.
 * Redis 3.0.x: If you choose to use this version to take advantage of the Redis built-in high availability and clustering, fail-over, replication and persistence features, it is important to note that, those new Redis 3.x features may impact the overall performance of reading from and writing data to the Redis cluster nodes.
	
4. Configure the DPS toolkit to connect to the data store from step 3. Copy the DPS toolkit sample configuration file from `STREAMS_INSTALL/samples/com.ibm.streamsx.dps/dp_test_1/etc/no-sql-kv-store-servers.cfg` to `your-project-directory/etc/no-sql-kv-store-servers.cfg`.If using the Redis v2.8.x store, specify `redis` in the configuration file; if using the Redis v3.x store, specify `redis-cluster` in the configuration file.  Each time you create a new SPL project, copy the configuration file from the example provided in the DPS toolkit to the /etc directory inside of your SPL project directory.  Make any configuration changes needed to the file, based on your application's needs. 

 
# Using the toolkit in SPL applications
All the functionality of the toolkit is available via the native functions in the `com.ibm.streamsx.store.distributed` and `com.ibm.streamsx.lock.distributed` namespaces. You need to include these namespaces in your SPL application via a use directive. 
See the "Getting Started" section below and the native function documentation has more details on how to use the toolkit within applications written in SPL.


# Using the toolkit in Java applications
Ensure that `&lt;dps_toolkit_home&gt;/impl/java/lib/dps-helper.jar`, which contains the Java implementation of the DPS functions is accessible to your application.  Packages of interest are `com.ibm.streamsx.dps` and `com.ibm.streamsx.dl`.
See the "Getting Started" section below and the  [../../javadoc/dps/index.html|Javadoc] for details on using the API from operators written in Java.

 
**Note regarding fusing Java operators:** 
Fusing two or more Java operators that utilize the Java DPS API requires that each operator have the same class path and the `@SharedLoader` annotation in its class definition.
For example:
	PrimitiveOperator(name="MyJavaOperator", namespace="com.ibm.demo",  description="Java Operator MyJavaOperator")
	@SharedLoader(true)
	public class MyJavaOperator extends AbstractOperator {
		...
	}
 
# Using the toolkit in C++ applications
Include the C++ header file `DistributedProcessStoreWrappers.h` found in `impl/include`.  This is the main entry point for the C++ functions, which are in the C++ namespace `com::ibm::streamsx::store::distributed`. 




# Getting Started
The following snippets demonstrate the basic usage of the toolkit from SPL and Java. Usage from C++ is very similar to the SPL example below.

SPL:

	rstring dummyRstring = "";
	uint32 dummyUint32 = 0u;
	mutable uint64 err = 0ul;
	mutable uint64 dbStore_handle = 0ul;
	dbStore_handle = dpsCreateStore("myDBStore1", dummyRstring, dummyUint32, err);
	
	if (err == 0ul ) { //no error occurred
		 //create lock for the store
		mutable uint64 lock_id = dlCreateOrGetLock("My db store lock", err);
		// Acquire the newly created lock, specifying a lease time and maximum time to wait to acquire the lock.
		float64 max_wait = 10.0;
		float64 lease_time = 10.0;
		dlAcquireLock(lock_id, lease_time, max_wait, err);
		//add a key/value pair to the store
		mutable boolean result = true;
		rstring key = "IBM";
		uint32 value = 399;
		err = 0ul;
		result = dpsPut(dbStore_handle, key, value, err);
		
		if (err != 0ul) {
			//use  dpsGetLastStoreErrorCode() and  dpsGetLastStoreErrorString() as needed
		}
		// finished our store operations, release the lock
		err = 0ul;
		dlReleaseLock(lock_id, err);	
	}


Java:	

	StoreFactory sf = DistributedStores.getStoreFactory();
	Store store = null;
	
	try {
	   //specify the SPL types for the keys and values in the store
	   String keyType = "rstring";
	   String valueType = "int32";
	   store = sf.createOrGetStore("Java Test Store1", keyType, valueType);
	} catch (StoreFactoryException sfe) {
		// use	sfe.getErrorCode() and  sfe.getErrorMessage()) for more info
	}
	
	...
	//once ready to access the store,
	//get the lock for the store, may have previously been created
	   LockFactory lf = DistributedLocks.getLockFactory(); 
	   Lock myLock = lf.createOrGetLock("Lock_For_Test_Store1");
	
	// Acquire the lock
	try {
	 	myLock.acquireLock();
	} catch (LockException le) {
		System.out.print("Unable to acquire the lock named 'Lock_For_Test_Store1'");
		System.out.println(" Error = " + le.getErrorCode() + ", Error msg = " + le.getErrorMessage());
	    throw le;
	}
	
	//perform store operations
	store.put("IBM", 39);
	store.put("Lenovo", 50);
	//release the lock  when finished
	myLock.releaseLock();
	
Note that error checking in the above examples is minimal.


# Error Handling in C++ and SPL
Most C++ functions include a mutable **err** parameter that will contain the result of executing the function.  If an error occurs, this variable's value will be non-zero.
It is the caller's responsibility to provide a mutable parameter to contain the error code and check its value afterwards.

In addition, there are functions that can be called when an error occurs to return the last error code and a message describing the error. 
The correct function to call after an operation depends on the operation that was last executed.
* For errors relating to the store functions, use `dpsGetLastStoreErrorCode()` and `dpsGetLastStoreErrorString()`.
* For errors related to the TTL functions, use `dpsGetLastStoreErrorCodeTTL()` and `dpsGetLastStoreErrorStringTTL()`.
* For locking related errors, use `dlGetLastDistributedLockErrorCode()` and `dlGetLastDistributedLockErrorString()`.

The following example shows how to check for errors, after a function call, in this case, after creating a lock:



	mutable uint64 err = 0ul;
	mutable uint64 lock_id = dlCreateOrGetLock("My Sentinel Lock1", err);
	
	if (err != 0ul) {
		rstring msg = dlGetLastDistributedLockErrorString();
		uint64 rc = dlGetLastDistributedLockErrorCode();
		printStringLn("Error creating lock, rc = " + (rstring)(rc) + ", msg =" + msg );
	}




# Additional Examples
To specifically learn how to call the DPS APIs from SPL native functions, C++ and Java primitive operators, download the SPL-Examples-For-Beginners-In-Streams4x.tar.gz package from [https://www.ibm.com/developerworks/community/files/app?lang=en#/file/414b8379-832d-424e-b0d5-ef63ed3500af | developerWorks]. 
The examples in that package explain how to call the DPS APIs from different parts of a Streams application. In particular, you may want to refer to the following three examples within the package:

* 058_data_sharing_between_non_fused_spl_custom_and_cpp_primitive_operators
* 061_data_sharing_between_non_fused_spl_custom_operators_and_a_native_function
* 062_data_sharing_between_non_fused_spl_custom_and_java_primitive_operators


# Reference information
[../../javadoc/dps/index.html| DPS Java API Reference]
  </info:description>
    <info:version>2.2.0</info:version>
    <info:requiredProductVersion>4.0.0.0</info:requiredProductVersion>
  </info:identity>
  <info:dependencies/>
  <info:sabFiles>
    <info:include path="impl/ext/**/*"/>
  </info:sabFiles>
</info:toolkitInfoModel>
